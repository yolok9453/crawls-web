name: Auto Update Daily Deals (PChome + Yahoo)

on:
  schedule:
    # 每 6 小時執行一次 (UTC 時間: 0, 6, 12, 18 點)
    - cron: '0 */6 * * *'
  workflow_dispatch:  # 允許手動觸發

jobs:
  update-daily-deals:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r config/requirements.txt
    
    - name: Install Chrome and ChromeDriver
      run: |
        # 更新套件列表
        sudo apt-get update
        
        # 安裝必要的依賴
        sudo apt-get install -y wget gnupg unzip curl xvfb
        
        # 添加 Google Chrome 的 GPG 金鑰和倉庫
        wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo gpg --dearmor -o /usr/share/keyrings/googlechrome-linux-keyring.gpg
        echo "deb [arch=amd64 signed-by=/usr/share/keyrings/googlechrome-linux-keyring.gpg] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
        
        # 更新套件列表並安裝 Chrome
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        
        # 檢查 Chrome 版本
        google-chrome --version
        
        # 設定虛擬顯示器 (確保穩定性)
        sudo Xvfb :99 -screen 0 1024x768x24 > /dev/null 2>&1 &
        export DISPLAY=:99
        
        # 手動安裝 ChromeDriver (不使用 webdriver-manager)
        echo "嘗試安裝 ChromeDriver..."
        
        # 方法1: 使用 apt 安裝 chromium-chromedriver
        sudo apt-get install -y chromium-chromedriver || true
        
        # 方法2: 手動下載最新版本
        echo "手動下載 ChromeDriver..."
        
        # 獲取 Chrome 主版本號
        CHROME_MAJOR_VERSION=$(google-chrome --version | grep -oP '\d+' | head -1)
        echo "Chrome 主版本: $CHROME_MAJOR_VERSION"
        
        # 下載最新的 ChromeDriver
        LATEST_VERSION=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/LATEST_RELEASE_$CHROME_MAJOR_VERSION")
        echo "下載 ChromeDriver 版本: $LATEST_VERSION"
        
        if [ ! -z "$LATEST_VERSION" ]; then
            wget -O /tmp/chromedriver.zip "https://storage.googleapis.com/chrome-for-testing-public/$LATEST_VERSION/linux64/chromedriver-linux64.zip"
            unzip /tmp/chromedriver.zip -d /tmp/
            sudo mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver
            sudo chmod +x /usr/local/bin/chromedriver
            echo "ChromeDriver 安裝完成"
        else
            echo "無法取得 ChromeDriver 版本，使用系統預設"
        fi
        
        # 驗證 ChromeDriver 可以正常工作
        python -c "
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.chrome.service import Service
        import os
        import warnings
        warnings.filterwarnings('ignore')
        
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--remote-debugging-port=9222')
        
        # 優先使用手動安裝的 ChromeDriver
        chromedriver_paths = [
            '/usr/local/bin/chromedriver',
            '/usr/bin/chromedriver',
            '/snap/bin/chromium.chromedriver'
        ]
        
        success = False
        working_driver_path = None
        
        for driver_path in chromedriver_paths:
            if os.path.exists(driver_path):
                try:
                    print(f'嘗試使用 ChromeDriver: {driver_path}')
                    service = Service(driver_path)
                    driver = webdriver.Chrome(service=service, options=options)
                    driver.get('https://www.google.com')
                    print(f'✅ ChromeDriver 測試成功 (路徑: {driver_path})')
                    working_driver_path = driver_path
                    driver.quit()
                    success = True
                    break
                except Exception as e:
                    print(f'❌ 路徑 {driver_path} 測試失敗: {e}')
                    continue
        
        if not success:
            # 最後嘗試使用系統 PATH 中的 chromedriver
            try:
                print('嘗試使用系統 PATH 中的 ChromeDriver...')
                driver = webdriver.Chrome(options=options)
                driver.get('https://www.google.com')
                print('✅ 系統 PATH ChromeDriver 測試成功')
                working_driver_path = 'chromedriver'
                driver.quit()
                success = True
            except Exception as e:
                print(f'❌ 系統 PATH ChromeDriver 失敗: {e}')
        
        if success:
            print(f'設定環境變數 CHROMEDRIVER_PATH={working_driver_path}')
            with open('/tmp/chromedriver_path.txt', 'w') as f:
                f.write(working_driver_path)
        else:
            print('❌ 所有 ChromeDriver 測試都失敗')
            exit(1)
        "

    - name: Prepare environment and check files
      run: |
        # 創建必要的目錄
        mkdir -p data
        mkdir -p crawl_testdata
        
        # 創建基本的 .env 檔案（不包含敏感資訊）
        echo "# GitHub Actions environment" > config/.env
        echo "FLASK_ENV=production" >> config/.env
        echo "FLASK_DEBUG=False" >> config/.env
        
        # 檢查爬蟲檔案是否存在
        echo "Checking crawler files:"
        ls -la crawlers/
        
        # 檢查 Python 路徑
        echo "Python path:"
        python -c "import sys; print('\n'.join(sys.path))"
        
        # 測試匯入爬蟲模組
        echo "Testing crawler imports:"
        python -c "
        import sys
        import os
        sys.path.insert(0, 'crawlers')
        sys.path.insert(0, 'core')
        try:
            from crawler_pchome_onsale import run as run_pchome
            print('✓ PChome crawler import successful')
        except Exception as e:
            print(f'✗ PChome crawler import failed: {e}')
        
        try:
            from crawler_yahoo_rushbuy import run as run_yahoo
            print('✓ Yahoo crawler import successful')
        except Exception as e:
            print(f'✗ Yahoo crawler import failed: {e}')
            
        try:
            from core.database import get_db_connection, init_db
            print('✓ Database module import successful')
        except Exception as e:
            print(f'✗ Database module import failed: {e}')
        "
    
    - name: Run Daily Deals Crawlers (PChome + Yahoo)
      env:
        DISPLAY: ":99"
      run: |
        python -c "
        import sys
        import os
        
        # 添加專案路徑
        current_dir = os.getcwd()
        sys.path.insert(0, current_dir)
        sys.path.insert(0, os.path.join(current_dir, 'crawlers'))
        sys.path.insert(0, os.path.join(current_dir, 'core'))
        
        # 設定環境變數
        os.environ['DISPLAY'] = ':99'
        
        # 讀取可用的 ChromeDriver 路徑
        chromedriver_path = None
        try:
            with open('/tmp/chromedriver_path.txt', 'r') as f:
                chromedriver_path = f.read().strip()
            print(f'使用 ChromeDriver 路徑: {chromedriver_path}')
            os.environ['CHROMEDRIVER_PATH'] = chromedriver_path
        except Exception as e:
            print(f'無法讀取 ChromeDriver 路徑: {e}')
        
        try:
            from crawler_pchome_onsale import run as run_pchome
            from crawler_yahoo_rushbuy import run as run_yahoo
            from core.database import get_db_connection, init_db
        except ImportError as e:
            print(f'匯入模組失敗: {e}')
            print('可用的檔案:')
            for root, dirs, files in os.walk('crawlers'):
                for file in files:
                    if file.endswith('.py'):
                        print(f'  {os.path.join(root, file)}')
            sys.exit(1)
        
        from datetime import datetime
        
        # 確保目錄存在
        os.makedirs('data', exist_ok=True)
        os.makedirs('crawl_testdata', exist_ok=True)
        
        # 初始化資料庫
        print('初始化資料庫...')
        init_db()
        
        current_time = datetime.now()
        total_saved = 0
        
        # 執行 PChome OnSale 爬蟲
        print('開始執行 PChome OnSale 爬蟲...')
        pchome_count = 0
        try:
            # 降低數量以確保穩定性，但仍有足夠的商品
            pchome_products = run_pchome(keyword='pchome_onsale', max_products=100)  # 平衡數量和穩定性
            
            if pchome_products:
                # 將資料存入 SQLite 資料庫
                conn = get_db_connection()
                cursor = conn.cursor()
                
                # 清除舊的 PChome OnSale 資料
                cursor.execute('DELETE FROM daily_deals WHERE platform = ?', ('pchome_onsale',))
                
                # 插入新資料
                for product in pchome_products:
                    try:
                        cursor.execute('''
                            INSERT INTO daily_deals 
                            (title, price, original_price, discount_percent, url, image_url, platform, crawl_time)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            product.get('title', ''),
                            product.get('price', 0),
                            product.get('original_price', 0),
                            product.get('discount_percent', 0.0),
                            product.get('url', ''),
                            product.get('image_url', ''),
                            'pchome_onsale',
                            current_time.isoformat()
                        ))
                        pchome_count += 1
                    except Exception as e:
                        print(f'插入 PChome 商品時發生錯誤: {e}')
                        continue
                
                conn.commit()
                conn.close()
                print(f'PChome 爬蟲執行完成！獲取並儲存 {pchome_count} 個商品到資料庫')
            else:
                print('PChome 爬蟲沒有獲取到商品，可能是網站結構變更')
        except Exception as e:
            print(f'PChome 爬蟲執行失敗: {e}')
            import traceback
            traceback.print_exc()
        
        # 執行 Yahoo 秒殺爬蟲
        print('開始執行 Yahoo 秒殺爬蟲...')
        yahoo_count = 0
        try:
            # 降低數量以確保穩定性，但仍有足夠的商品
            yahoo_products = run_yahoo(keyword='yahoo_rushbuy', max_products=80)  # 平衡數量和穩定性
            
            if yahoo_products:
                # 將資料存入 SQLite 資料庫
                conn = get_db_connection()
                cursor = conn.cursor()
                
                # 清除舊的 Yahoo 秒殺資料
                cursor.execute('DELETE FROM daily_deals WHERE platform = ?', ('yahoo_rushbuy',))
                
                # 插入新資料
                for product in yahoo_products:
                    try:
                        cursor.execute('''
                            INSERT INTO daily_deals 
                            (title, price, original_price, discount_percent, url, image_url, platform, crawl_time)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            product.get('title', ''),
                            product.get('price', 0),
                            product.get('original_price', 0),
                            product.get('discount_percent', 0.0),
                            product.get('url', ''),
                            product.get('image_url', ''),
                            'yahoo_rushbuy',
                            current_time.isoformat()
                        ))
                        yahoo_count += 1
                    except Exception as e:
                        print(f'插入 Yahoo 商品時發生錯誤: {e}')
                        continue
                
                conn.commit()
                conn.close()
                print(f'Yahoo 爬蟲執行完成！獲取並儲存 {yahoo_count} 個商品到資料庫')
            else:
                print('Yahoo 爬蟲沒有獲取到商品，可能是網站結構變更')
        except Exception as e:
            print(f'Yahoo 爬蟲執行失敗: {e}')
            import traceback
            traceback.print_exc()
        
        total_saved = pchome_count + yahoo_count
        print(f'全部爬蟲執行完成！PChome: {pchome_count}個, Yahoo: {yahoo_count}個，總共儲存 {total_saved} 個商品到資料庫')
        
        # 即使有部分失敗，只要有任一爬蟲成功就算成功
        if total_saved == 0:
            print('所有爬蟲都失敗了，沒有儲存任何商品')
            sys.exit(1)
        else:
            print(f'成功儲存 {total_saved} 個商品到資料庫')
        "
    
    - name: Configure Git
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
    
    - name: Commit and push changes
      run: |
        # 檢查是否有檔案需要提交（資料庫檔案）
        git add data/crawler_data.db || true
        
        # 檢查是否有變更
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          echo "Found changes, committing..."
          git commit -m "Auto update daily deals database (PChome + Yahoo) - $(date '+%Y-%m-%d %H:%M:%S UTC')" || true
          git push || echo "Push failed, but continuing..."
        fi
