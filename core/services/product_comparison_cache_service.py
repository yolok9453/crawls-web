"""
å•†å“æ¯”è¼ƒå¿«å–æœå‹™
è² è²¬å•†å“æ¯”è¼ƒçµæœçš„å¿«å–ç®¡ç†å’Œå€™é¸å•†å“ç²å–
"""

import json
from datetime import datetime
from core.database import get_db_connection


class ProductComparisonCacheService:
    def __init__(self, crawler_manager, product_comparison_service):
        self.crawler_manager = crawler_manager
        self.product_comparison_service = product_comparison_service
    
    def get_candidate_products_from_database(self, target_product):
        """å¾å·²çˆ¬å–çš„è³‡æ–™åº«ä¸­ç²å–å€™é¸å•†å“ï¼Œä¸é‡æ–°çˆ¬å–"""
        try:
            target_title = target_product.get('title', '')
            target_platform = target_product.get('platform', '')
            
            # æå–é—œéµè©ç”¨æ–¼è³‡æ–™åº«æœå°‹
            keywords_to_remove = ['ã€', 'ã€‘', 'â˜…', 'â˜†', 'â–¶', 'â–·', 'â€»', 'â—†', 'â—‡', 'â– ', 'â–¡', 
                                 'é™æ™‚', 'ç‰¹åƒ¹', 'ä¿ƒéŠ·', 'å„ªæƒ ', 'æŠ˜æ‰£', 'å…é‹', 'ç¾è²¨', 'ç†±éŠ·',
                                 'æ–°æ¬¾', '2024', '2025', 'æ­£å“', 'å®˜æ–¹', 'ä»£ç†', 'å…¬å¸è²¨']
            
            search_keyword = target_title
            for remove_word in keywords_to_remove:
                search_keyword = search_keyword.replace(remove_word, '')
            
            # é€²ä¸€æ­¥ç°¡åŒ–é—œéµè©
            if '(' in search_keyword:
                search_keyword = search_keyword.split('(')[0].strip()
            elif 'ï¼ˆ' in search_keyword:
                search_keyword = search_keyword.split('ï¼ˆ')[0].strip()
            
            # æå–å“ç‰Œæˆ–ä¸»è¦é—œéµè©
            words = search_keyword.strip().split()
            if len(words) > 1:
                # å–å‰2-3å€‹é—œéµè©
                key_words = words[:3]
            else:
                key_words = words
            
            print(f"ğŸ” å¾è³‡æ–™åº«æœå°‹é—œéµè©: {key_words}")
            
            candidate_products = []
            conn = get_db_connection()
            
            # å¾ daily_deals è¡¨æœå°‹ï¼ˆæ’é™¤è‡ªå·±ï¼‰
            for keyword in key_words:
                if len(keyword) >= 2:  # åªæœå°‹é•·åº¦>=2çš„é—œéµè©
                    cursor = conn.execute("""
                        SELECT title, platform, price, url, image_url, 'daily_deals' as source_table
                        FROM daily_deals 
                        WHERE title LIKE ? AND platform != ?
                        ORDER BY crawl_time DESC
                        LIMIT 50
                    """, (f'%{keyword}%', target_platform))
                    
                    results = cursor.fetchall()
                    for row in results:
                        candidate_product = {
                            'title': row['title'],
                            'platform': row['platform'],
                            'price': row['price'],
                            'url': row['url'],
                            'image_url': row['image_url'],
                            'source_table': row['source_table']
                        }
                        # é¿å…é‡è¤‡
                        if not any(p['url'] == candidate_product['url'] for p in candidate_products):
                            candidate_products.append(candidate_product)
            
            # å¾ products è¡¨æœå°‹ï¼ˆå¦‚æœ daily_deals çµæœä¸è¶³ï¼‰
            if len(candidate_products) < 20:
                for keyword in key_words:
                    if len(keyword) >= 2:
                        cursor = conn.execute("""
                            SELECT title, platform, price, url, image_url, 'products' as source_table
                            FROM products 
                            WHERE title LIKE ? AND platform != ?
                            ORDER BY id DESC
                            LIMIT 30
                        """, (f'%{keyword}%', target_platform))
                        
                        results = cursor.fetchall()
                        for row in results:
                            candidate_product = {
                                'title': row['title'],
                                'platform': row['platform'],
                                'price': row['price'],
                                'url': row['url'],
                                'image_url': row['image_url'],
                                'source_table': row['source_table']
                            }
                            # é¿å…é‡è¤‡
                            if not any(p['url'] == candidate_product['url'] for p in candidate_products):
                                candidate_products.append(candidate_product)
            
            conn.close()
            
            print(f"ğŸ“Š å¾è³‡æ–™åº«æ‰¾åˆ° {len(candidate_products)} å€‹å€™é¸å•†å“")
            return candidate_products[:50]  # é™åˆ¶æ•¸é‡
            
        except Exception as e:
            print(f"å¾è³‡æ–™åº«ç²å–å€™é¸å•†å“æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def get_candidate_products_for_comparison(self, target_product):
        """ç²å–ç”¨æ–¼æ¯”è¼ƒçš„å€™é¸å•†å“ - å„ªå…ˆä½¿ç”¨è³‡æ–™åº«æœå°‹"""
        try:
            # é¦–å…ˆå¾è³‡æ–™åº«æœå°‹
            candidate_products = self.get_candidate_products_from_database(target_product)
            
            if len(candidate_products) >= 5:  # å¦‚æœè³‡æ–™åº«æœ‰è¶³å¤ çš„å€™é¸å•†å“
                print(f"âœ… ä½¿ç”¨è³‡æ–™åº«æœå°‹çµæœ: {len(candidate_products)} å€‹å€™é¸å•†å“")
                return candidate_products
            
            # å¦‚æœè³‡æ–™åº«çµæœä¸è¶³ï¼Œæ‰é€²è¡Œå³æ™‚çˆ¬å–ï¼ˆä½œç‚ºå‚™ç”¨ï¼‰
            print(f"âš ï¸ è³‡æ–™åº«å€™é¸å•†å“ä¸è¶³({len(candidate_products)}å€‹)ï¼Œä½¿ç”¨å³æ™‚çˆ¬å–ä½œç‚ºè£œå……...")
            return self.get_candidate_products_from_crawling(target_product)
            
        except Exception as e:
            print(f"ç²å–å€™é¸å•†å“æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def get_candidate_products_from_crawling(self, target_product):
        """å¾å³æ™‚çˆ¬å–ç²å–å€™é¸å•†å“ï¼ˆå‚™ç”¨æ–¹æ³•ï¼‰"""
        try:
            target_title = target_product.get('title', '')
            
            # æå–é—œéµè©ç”¨æ–¼çˆ¬å–
            keywords_to_remove = ['ã€', 'ã€‘', 'â˜…', 'â˜†', 'â–¶', 'â–·', 'â€»', 'â—†', 'â—‡', 'â– ', 'â–¡', 
                                 'é™æ™‚', 'ç‰¹åƒ¹', 'ä¿ƒéŠ·', 'å„ªæƒ ', 'æŠ˜æ‰£', 'å…é‹', 'ç¾è²¨', 'ç†±éŠ·',
                                 'æ–°æ¬¾', '2024', '2025', 'æ­£å“', 'å®˜æ–¹', 'ä»£ç†', 'å…¬å¸è²¨']
            
            search_keyword = target_title
            for remove_word in keywords_to_remove:
                search_keyword = search_keyword.replace(remove_word, '')
            
            # é€²ä¸€æ­¥ç°¡åŒ–é—œéµè©
            if '(' in search_keyword:
                search_keyword = search_keyword.split('(')[0].strip()
            elif 'ï¼ˆ' in search_keyword:
                search_keyword = search_keyword.split('ï¼ˆ')[0].strip()
            
            words = search_keyword.strip().split()
            if len(words) > 3:
                search_keyword = ' '.join(words[:3])
            else:
                search_keyword = search_keyword.strip()
            
            # å³æ™‚çˆ¬å–å„å¹³å°çš„å€™é¸å•†å“
            candidate_products = []
            crawl_platforms = ['carrefour', 'pchome', 'yahoo', 'routn']
            
            for platform in crawl_platforms:
                try:
                    crawl_result = self.crawler_manager.run_single_crawler(
                        platform=platform,
                        keyword=search_keyword,
                        max_products=30,  # æ¸›å°‘æ•¸é‡ä»¥åŠ å¿«è™•ç†é€Ÿåº¦
                        min_price=0,
                        max_price=999999
                    )
                    
                    if crawl_result['status'] == 'success' and crawl_result['products']:
                        for product in crawl_result['products']:
                            candidate_product = {
                                'title': product.get('title') or product.get('name', ''),
                                'platform': platform,
                                'price': product.get('price', 0),
                                'url': product.get('url', ''),
                                'image_url': product.get('image_url', ''),
                                'source_table': 'live_crawl'
                            }
                            candidate_products.append(candidate_product)
                            
                except Exception as e:
                    print(f"çˆ¬å– {platform} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue
            
            return candidate_products
            
        except Exception as e:
            print(f"ç²å–å€™é¸å•†å“æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def precompute_comparison_results(self):
        """é å…ˆè¨ˆç®—æ‰€æœ‰æ¯æ—¥ä¿ƒéŠ·å•†å“çš„æ¯”è¼ƒçµæœä¸¦å­˜å…¥å¿«å–"""
        try:
            print("é–‹å§‹é å…ˆè¨ˆç®—å•†å“æ¯”è¼ƒçµæœ...")
            
            conn = get_db_connection()
            cursor = conn.cursor()
            
            # æ¸…é™¤èˆŠçš„æ¯”è¼ƒçµæœå¿«å–
            cursor.execute("DELETE FROM product_comparison_cache")
            conn.commit()
            print("å·²æ¸…é™¤èˆŠçš„æ¯”è¼ƒçµæœå¿«å–")
            
            # ç²å–æ‰€æœ‰æ¯æ—¥ä¿ƒéŠ·å•†å“
            daily_deals = conn.execute("SELECT * FROM daily_deals ORDER BY crawl_time DESC").fetchall()
            print(f"æ‰¾åˆ° {len(daily_deals)} å€‹æ¯æ—¥ä¿ƒéŠ·å•†å“éœ€è¦è¨ˆç®—æ¯”è¼ƒçµæœ")
            
            processed_count = 0
            
            for deal in daily_deals:
                try:
                    target_product = {
                        'title': deal['title'],
                        'platform': deal['platform'],
                        'price': deal['price']
                    }
                    
                    print(f"è¨ˆç®—å•†å“ {deal['title'][:30]}... çš„æ¯”è¼ƒçµæœ")
                    
                    # ä½¿ç”¨ç›¸åŒçš„é‚è¼¯ç²å–å€™é¸å•†å“
                    candidate_products = self.get_candidate_products_for_comparison(target_product)
                    
                    if candidate_products:
                        # ä½¿ç”¨ AI æˆ–å‚™ç”¨æ–¹æ³•é€²è¡Œæ¯”è¼ƒ
                        matches = self.product_comparison_service.compare_products(target_product, candidate_products)
                        
                        # å°‡æ¯”è¼ƒçµæœå­˜å…¥å¿«å–
                        cache_entries = []
                        for match in matches:
                            similarity = match.get('similarity', 0)
                            if similarity >= 0.70:  # åªå¿«å–é«˜ç›¸ä¼¼åº¦çš„çµæœ
                                try:
                                    product_index = match['index']
                                    if 0 <= product_index < len(candidate_products):
                                        candidate = candidate_products[product_index]
                                        
                                        # å°‡å€™é¸å•†å“å­˜å…¥ products è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                                        cursor.execute("""
                                            INSERT OR IGNORE INTO products 
                                            (session_id, platform, title, price, url, image_url) 
                                            VALUES (?, ?, ?, ?, ?, ?)
                                        """, (
                                            -1,  # ç‰¹æ®Š session_id è¡¨ç¤ºé€™æ˜¯æ¯”è¼ƒç”¨çš„å•†å“
                                            candidate['platform'],
                                            candidate['title'],
                                            candidate['price'],
                                            candidate['url'],
                                            candidate.get('image_url', '')
                                        ))
                                        
                                        # ç²å–å‰›æ’å…¥æˆ–å·²å­˜åœ¨çš„å•†å“ID
                                        product_id = cursor.execute(
                                            "SELECT id FROM products WHERE url = ?", 
                                            (candidate['url'],)
                                        ).fetchone()['id']
                                        
                                        cache_entries.append((
                                            deal['id'],
                                            product_id,
                                            similarity,
                                            match.get('reason', ''),
                                            match.get('confidence', ''),
                                            match.get('category', ''),
                                            datetime.now().isoformat()
                                        ))
                                        
                                except Exception as e:
                                    print(f"è™•ç†åŒ¹é…çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                                    continue
                        
                        # æ‰¹é‡æ’å…¥å¿«å–çµæœ
                        if cache_entries:
                            cursor.executemany("""
                                INSERT INTO product_comparison_cache 
                                (target_product_id, similar_product_id, similarity, reason, confidence, category, cache_time)
                                VALUES (?, ?, ?, ?, ?, ?, ?)
                            """, cache_entries)
                            conn.commit()
                            print(f"ç‚ºå•†å“ {deal['title'][:30]}... å¿«å–äº† {len(cache_entries)} å€‹æ¯”è¼ƒçµæœ")
                        
                        processed_count += 1
                        
                        # æ¯è™•ç†10å€‹å•†å“å°±é¡¯ç¤ºé€²åº¦
                        if processed_count % 10 == 0:
                            print(f"å·²è™•ç† {processed_count}/{len(daily_deals)} å€‹å•†å“")
                    
                except Exception as e:
                    print(f"è¨ˆç®—å•†å“ {deal['title'][:30]}... çš„æ¯”è¼ƒçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue
            
            conn.close()
            print(f"é å…ˆè¨ˆç®—å®Œæˆï¼Œå…±è™•ç† {processed_count} å€‹å•†å“")
            
        except Exception as e:
            print(f"é å…ˆè¨ˆç®—æ¯”è¼ƒçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
    
    def get_cached_comparison(self, target_product_name, target_platform, target_price):
        """å¾å¿«å–ä¸­ç²å–å•†å“æ¯”è¼ƒçµæœ"""
        try:
            conn = get_db_connection()
            
            # æŸ¥æ‰¾å°æ‡‰çš„æ¯æ—¥ä¿ƒéŠ·å•†å“
            daily_deal = conn.execute("""
                SELECT * FROM daily_deals 
                WHERE title = ? AND platform = ? AND price = ?
                ORDER BY crawl_time DESC 
                LIMIT 1
            """, (target_product_name, target_platform, target_price)).fetchone()
            
            if daily_deal:
                print(f"æ‰¾åˆ°å°æ‡‰çš„æ¯æ—¥ä¿ƒéŠ·å•†å“ï¼ŒID: {daily_deal['id']}")
                
                # å¾å¿«å–ä¸­ç²å–æ¯”è¼ƒçµæœ
                cached_results = conn.execute("""
                    SELECT pcc.*, p.title, p.platform, p.price, p.url, p.image_url
                    FROM product_comparison_cache pcc
                    JOIN products p ON pcc.similar_product_id = p.id
                    WHERE pcc.target_product_id = ?
                    ORDER BY pcc.similarity DESC
                """, (daily_deal['id'],)).fetchall()
                
                conn.close()
                
                if cached_results:
                    print(f"å¾å¿«å–ä¸­æ‰¾åˆ° {len(cached_results)} å€‹æ¯”è¼ƒçµæœ")
                    
                    # è½‰æ›ç‚ºå‰ç«¯éœ€è¦çš„æ ¼å¼
                    similar_products = []
                    for result in cached_results:
                        similar_products.append({
                            'title': result['title'],
                            'platform': result['platform'],
                            'price': result['price'],
                            'url': result['url'],
                            'image_url': result['image_url'],
                            'similarity': result['similarity'],
                            'reason': result['reason'],
                            'confidence': result['confidence'],
                            'category': result['category'],
                            'source_table': 'cache'
                        })
                    
                    return {
                        'similarProducts': similar_products,
                        'totalCandidates': len(similar_products),
                        'totalMatches': len(similar_products),
                        'targetProduct': {
                            'title': target_product_name,
                            'platform': target_platform,
                            'price': target_price
                        },
                        'source': 'cache'
                    }
            
            conn.close()
            return None
            
        except Exception as e:
            print(f"å¾å¿«å–ç²å–æ¯”è¼ƒçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def compare_products_realtime(self, target_product):
        """å³æ™‚å•†å“æ¯”è¼ƒï¼ˆç•¶å¿«å–ä¸­æ²’æœ‰çµæœæ™‚ä½¿ç”¨ï¼‰"""
        try:
            print("å¿«å–ä¸­æ²’æœ‰æ‰¾åˆ°çµæœï¼Œå›é€€åˆ°å³æ™‚è¨ˆç®—...")
            
            # ç²å–å€™é¸å•†å“
            candidate_products = self.get_candidate_products_for_comparison(target_product)
            
            if not candidate_products:
                print("è­¦å‘Š: æ²’æœ‰å€™é¸å•†å“å¯ä¾›æ¯”è¼ƒ")
                return {
                    'similarProducts': [], 
                    'totalCandidates': 0,
                    'message': 'æ²’æœ‰å€™é¸å•†å“å¯ä¾›æ¯”è¼ƒ'
                }

            print("é–‹å§‹èª¿ç”¨ AI é€²è¡Œå•†å“æ¯”è¼ƒ...")
            matches = self.product_comparison_service.compare_products(target_product, candidate_products)
            print(f"AI å›å‚³ {len(matches)} å€‹åŒ¹é…çµæœ")
            
            similar_products = []
            for i, match in enumerate(matches):            
                similarity = match.get('similarity', 0)
                if similarity >= 0.70:
                    try:
                        product_index = match['index']
                        if 0 <= product_index < len(candidate_products):
                            product = candidate_products[product_index]
                            product['similarity'] = similarity
                            product['reason'] = match.get('reason', '')
                            product['confidence'] = match.get('confidence', '')
                            product['category'] = match.get('category', '')
                            similar_products.append(product)
                    except (IndexError, KeyError) as e:
                        print(f"è§£ææ¯”è¼ƒçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                        continue

            similar_products.sort(key=lambda x: x.get('similarity', 0), reverse=True)
            
            return {
                'similarProducts': similar_products,
                'totalCandidates': len(candidate_products),
                'totalMatches': len(matches),
                'targetProduct': target_product,
                'source': 'realtime'
            }
            
        except Exception as e:
            print(f"å³æ™‚å•†å“æ¯”è¼ƒæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
            raise e
